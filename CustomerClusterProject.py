# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UyOg7kHfgsN3iG6U8OUumU6aGw5dSy1-
"""

import numpy as np                     # Numerical operations, arrays, random numbers
import pandas as pd                   # Data manipulation and analysis (DataFrames)
import matplotlib                      # Core matplotlib library
import datetime                        # Working with date and time objects
import matplotlib.pyplot as plt        # Plotting graphs and visualizations
from matplotlib import colors          # Color mapping utilities for visualizations
import seaborn as sns                  # Statistical data visualization (built on matplotlib)

from sklearn.preprocessing import LabelBinarizer   # Converts categorical labels into binary/one-hot encoding
from sklearn.preprocessing import LabelEncoder     # Converts categorical labels into numerical values
from sklearn.preprocessing import StandardScaler    # Standardizes features (mean=0, variance=1)
from sklearn.decomposition import PCA               # Principal Component Analysis for dimensionality reduction
from yellowbrick.cluster import KElbowVisualizer   # Helps determine optimal clusters using Elbow method (visualizer)
from sklearn.cluster import KMeans                  # K-Means clustering algorithm
from mpl_toolkits.mplot3d import Axes3D             # 3D plotting tools for matplotlib
from sklearn.cluster import AgglomerativeClustering # Hierarchical clustering algorithm
from matplotlib.colors import ListedColormap        # Create custom color maps for plots
from sklearn import metrics                         # Evaluation metrics (silhouette score, etc.)

import warnings                                     # For controlling warnings
import sys                                          # System-level operations (e.g., checking Python warnings)

# Disable warnings if not already suppressed
if not sys.warnoptions:
    warnings.simplefilter("Ignore")

# Set the random seed for reproducibility
np.random.seed(42)

#Loading the dataset
data = pd.read_csv('/content/marketing_campaign.csv',sep="\t")
print("Number of datapts:", len(data))
data.head()

#Infomation on data
data.info()

#remove na values
data=data.dropna()
print("Data points after removing the Missing values:",len(data))
#data.info()

#converting Dt_Customer column to date time
data["Dt_Customer"] = pd.to_datetime(data["Dt_Customer"],dayfirst=True)
dates=[]
for i in data["Dt_Customer"]:
  i =i.date()
  dates.append(i)
print("Newest Customer's enrollment: ",max(dates))
print("Oldest Customer's enrollment: ",min(dates))

#create a feature "Customer_For"
days=[]
d1= max(dates)
for i in dates:
  delta = d1 -i
  days.append(delta)
data["Customer_For"] = days
data["Customer_For"] =pd.to_numeric(data["Customer_For"],errors="coerce")

#Getting count of Martial Status and Education Feature
print("Categories in Marital_Status feature\n",data["Marital_Status"].value_counts(),"\n")
print("Categories in Education feature\n",data["Education"].value_counts(),"\n")

#Feature Engineering

#Age of Customer
data["Age"] = 2025-data["Year_Birth"]

#For clarity: renamed Mnt to actual names (moved this up)
data=data.rename(columns={"MntWines":"Wines","MntFruits":"Fruits","MntMeatProducts":"Meat","MntFishProducts":"Fish","MntSweetProducts":"Sweets","MntGoldProds":"Gold"})

#Total spending on items (now uses new names)
data["Spent"] = data["Wines"]+data["Fish"]+data["Meat"]+data["Fruits"]+data["Sweets"]+data["Gold"]

#How many people living "Alone"
data["Living_With"] = data["Marital_Status"].replace({"Married":"Partner","Together":"Partner","Absurd":"Alone","Widow":"Alone","YOLO":"Alone","Divorced":"Alone","Single":"Alone"})

#Children in Household
data["Children"] = data["Kidhome"]+data["Teenhome"]

#Total members in Household
# Fixed TypeError by explicitly mapping and ensuring numeric type
data["Family_Size"] = data["Living_With"].map({"Alone":1,"Partner":2}).astype(int) + data["Children"]

#Pertaining Parenthood
data["Is_Parent"] = np.where(data.Children>0,1,0)

# Segemnting Education Levels
data["Education"]=data["Education"].replace({"Basic":"Undergraduate","2n Cycle":"Ungergraduate","Graduation":"Graduate","Master":"PostGraduate","PhD":"PostGraduate"})

#dropping some of the redundant features
to_drop = ["Marital_Status","Dt_Customer","Z_CostContact","Z_Revenue","Year_Birth","ID"]
data = data.drop(to_drop,axis=1)

#Loading the dataset
data = pd.read_csv('/content/marketing_campaign.csv',sep="\t")
print("Number of datapts:", len(data))
data.head()

#remove na values
data=data.dropna()
print("Data points after removing the Missing values:",len(data))

#converting Dt_Customer column to date time
data["Dt_Customer"] = pd.to_datetime(data["Dt_Customer"],dayfirst=True)
dates=[]
for i in data["Dt_Customer"]:
  i =i.date()
  dates.append(i)
print("Newest Customer's enrollment: ",max(dates))
print("Oldest Customer's enrollment: ",min(dates))

#create a feature "Customer_For"
days=[]
d1= max(dates)
for i in dates:
  delta = d1 -i
  days.append(delta)
data["Customer_For"] = days
data["Customer_For"] =pd.to_numeric(data["Customer_For"].dt.days,errors="coerce") # Ensure conversion to numeric days

#Feature Engineering

#Age of Customer
data["Age"] = 2025-data["Year_Birth"]

#For clarity: renamed Mnt to actual names (moved this up)
data=data.rename(columns={"MntWines":"Wines","MntFruits":"Fruits","MntMeatProducts":"Meat","MntFishProducts":"Fish","MntSweetProducts":"Sweets","MntGoldProds":"Gold"})

#Total spending on items (now uses new names)
data["Spent"] = data["Wines"]+data["Fish"]+data["Meat"]+data["Fruits"]+data["Sweets"]+data["Gold"]

#How many people living "Alone"
data["Living_With"] = data["Marital_Status"].replace({"Married":"Partner","Together":"Partner","Absurd":"Alone","Widow":"Alone","YOLO":"Alone","Divorced":"Alone","Single":"Alone"})

#Children in Household
data["Children"] = data["Kidhome"]+data["Teenhome"]

#Total members in Household
# Fixed TypeError by explicitly mapping and ensuring numeric type
data["Family_Size"] = data["Living_With"].map({"Alone":1,"Partner":2}).astype(int) + data["Children"]

#Pertaining Parenthood
data["Is_Parent"] = np.where(data.Children>0,1,0)

# Segemnting Education Levels
data["Education"]=data["Education"].replace({"Basic":"Undergraduate","2n Cycle":"Undergraduate","Graduation":"Graduate","Master":"PostGraduate","PhD":"PostGraduate"})

#dropping some of the redundant features
to_drop = ["Marital_Status","Dt_Customer","Z_CostContact","Z_Revenue","Year_Birth","ID"]
data = data.drop(to_drop,axis=1)

#dropping the outliers by setting a cap on Age and Income
data = data[data["Age"]<90]
data = data[data["Income"]<600000]
print("Total number of data points after removing the outliers are:", len(data))

data.describe()

data.describe()

#dropping the outliers by setting a cap on Age and Income
data = data[data["Age"]<90]
data = data[data["Income"]<600000]
print("Total number of data points after removing the outliers are:", len(data))

#To plot some selected features

#Setting up colors preferences
sns.set(rc={"axes.facecolor":"#FFF9ED","figure.facecolor":"#FFF9ED"})
pallet = ["#682F2F","#9E726F","#D68281","#B9C0C9","#9F8A78","#F3AB60"]
cmap = colors.ListedColormap(["#682F2F","#9E726F","#D68281","#B9C0C9","#9F8A78","#F3AB60"])

#plotting following features
To_plot = ["Income","Recency","Customer_For","Age","Spent","Is_Parent"]
plt.figure()
sns.pairplot(data[To_plot],hue="Is_Parent",palette=(["#682F2F","#F3AB60"]))

#Taking hue
plt.show()

data.info()

#Get list of categorical values
s = (data.dtypes == 'object')
object_cols = list(s[s].index)

print("Categorical variables:",object_cols)

#label encoding the object dtypes
LE = LabelEncoder()
for i in object_cols:
  data[i]=data[[i]].apply(LE.fit_transform)

print("All features are now numerical")

data.info()

#Creating a copy of data
ds = data.copy()
#creating a subset of dataframe by dropping the feaatures on deals accepted and promotions
cols_del = ['AcceptedCmp3','AcceptedCmp4','AcceptedCmp5','AcceptedCmp1','AcceptedCmp2','Complain','Response']
ds = ds.drop(cols_del,axis=1)
#scaling
scaler = StandardScaler()
scaler.fit(ds)
scaled_ds = pd.DataFrame(scaler.transform(ds),columns=ds.columns)
print("All features are now scaled")

#scaled data to be used for reducing the dimensionality
print("Dataframe to be used for further modelling:")
scaled_ds.head()

#Initiating PCA to reduce dimensions aka features to 3
pca = PCA(n_components=3)
pca.fit(scaled_ds)
PCA_ds = pd.DataFrame(pca.transform(scaled_ds),columns=(["col1","col2","col3"]))
PCA_ds.describe().T

#A 3D Projection of Data in the Reduced Dimension
x = PCA_ds["col1"]
y = PCA_ds["col2"]
z = PCA_ds["col3"]
#To plot
fig = plt.figure(figsize=(10,8))
ax = fig.add_subplot(111,projection="3d")
ax.scatter(x,y,z,c="maroon",marker="o")
ax.set_title("3D Projection of Data in the Reduced Dimension")
plt.show()

#Quick exaxmination of elbow method to find numbers of clusters to make.
print('Elbow Method to determine the number of clusters to be formed:')
Elbow_M = KElbowVisualizer(KMeans(),k=10)
Elbow_M.fit(PCA_ds)
Elbow_M.show()

#Initiating the Agglomerative Clustering model
AC = AgglomerativeClustering(n_clusters=4)
#fit model and predict clusters
yhat_AC = AC.fit_predict(PCA_ds)
PCA_ds["Clusters"] = yhat_AC
#Adding the clusters feature to the original dataframe.
data["Clusters"] = yhat_AC

# Initiating the Agglomerative Clustering model
AC = AgglomerativeClustering(n_clusters=4)
#fit model and predict clusters
yhat_AC = AC.fit_predict(PCA_ds[['col1', 'col2', 'col3']]) # Use only PCA components for clustering
PCA_ds["Clusters"] = yhat_AC
#Adding the clusters feature to the original dataframe.
data["Clusters"] = yhat_AC # Also update original data with clusters

fig = plt.figure(figsize=(10,8))
ax = plt.subplot(111,projection="3d",label="bla")
ax.scatter(x,y,z,s=40,c=PCA_ds["Clusters"],marker='o',cmap=cmap)
ax.set_title("Plot of Clusters")
plt.show()

#plotting countplot of clusters
pal = ["#682F2F","#B9C0C9","#9F8A78","#F3AB60"]
pl = sns.countplot(x=data["Clusters"],palette=pal)
pl.set_title("Countplot of Clusters")
plt.show()

pl = sns.scatterplot(data = data, x=data["Spent"],y=data["Income"],hue=data["Clusters"],palette=pal)
pl.set_title("Scatterplot of Income vs Spent")
plt.legend()
plt.show()

plt.figure()
pl=sns.swarmplot(x=data["Clusters"], y=data["Spent"], color="#CBEDDD",alpha=0.5)
pl=sns.boxenplot(x=data["Clusters"], y=data["Spent"], palette=pal, hue=data["Clusters"], legend=False)
plt.show()

#creating a feature to get a sum of accepted promotions
data["Total_Promos"] = data["AcceptedCmp3"]+data["AcceptedCmp4"]+data["AcceptedCmp5"]+data["AcceptedCmp2"]+data["AcceptedCmp1"]
plt.figure()
pl = sns.countplot(x=data["Total_Promos"],palette=pal,hue=data["Clusters"])
pl.set_title("Countplot of Total Promotions")
pl.set_xlabel("Total Promotions")
plt.show()

#plotting the number of deals purchased
plt.figure()
pl=sns.boxenplot(x=data["Clusters"], y=data["NumDealsPurchases"], palette=pal)
pl.set_title("Number of Deals Purchased", fontsize=20)
plt.show()

Personal = ["Kidhome","Teenhome","Customer_For","Age","Children","Family_Size","Is_Parent","Education","Living_With"]

for i in Personal:
  plt.figure()
  sns.jointplot(x=data[i],y=data["Spent"],kind="kde",hue=data["Clusters"],palette=pal)
  plt.show()
